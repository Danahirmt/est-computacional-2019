<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>10.8 HMC y Stan | Estadística Computacional</title>
  <meta name="description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2019." />
  <meta name="generator" content="bookdown 0.15.1 and GitBook 2.6.7" />

  <meta property="og:title" content="10.8 HMC y Stan | Estadística Computacional" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2019." />
  <meta name="github-repo" content="tereom/est-computacional-2019" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="10.8 HMC y Stan | Estadística Computacional" />
  
  <meta name="twitter:description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2019." />
  

<meta name="author" content="María Teresa Ortiz" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="muestreador-de-gibbs.html"/>
<link rel="next" href="diagnósticos-generales.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/d3-3.5.6/d3.min.js"></script>
<link href="libs/profvis-0.3.6/profvis.css" rel="stylesheet" />
<script src="libs/profvis-0.3.6/profvis.js"></script>
<link href="libs/highlight-6.2.0/textmate.css" rel="stylesheet" />
<script src="libs/highlight-6.2.0/highlight.js"></script>
<script src="libs/profvis-binding-0.3.6/profvis.js"></script>
<script src="libs/plotly-binding-4.9.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.49.4/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.49.4/plotly-latest.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
<link rel="stylesheet" href="css/font-awesome.min.css" type="text/css" />
<link rel="stylesheet" href="css/cajas.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística Computacional</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Información del curso</a><ul>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html"><i class="fa fa-check"></i>Temario</a><ul>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#calificación"><i class="fa fa-check"></i>Calificación</a></li>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#otros-recursos"><i class="fa fa-check"></i>Otros recursos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="noticias.html"><a href="noticias.html"><i class="fa fa-check"></i>Noticias</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="principios-visualización.html"><a href="principios-visualización.html"><i class="fa fa-check"></i><b>1</b> Principios visualización</a><ul>
<li class="chapter" data-level="1.1" data-path="introducción.html"><a href="introducción.html"><i class="fa fa-check"></i><b>1.1</b> Introducción</a><ul>
<li class="chapter" data-level="" data-path="introducción.html"><a href="introducción.html#visualización-de-datos-en-la-estadística"><i class="fa fa-check"></i>Visualización de datos en la estadística</a></li>
<li class="chapter" data-level="" data-path="introducción.html"><a href="introducción.html#visualización-popular-de-datos"><i class="fa fa-check"></i>Visualización popular de datos</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="teoría-de-visualización-de-datos.html"><a href="teoría-de-visualización-de-datos.html"><i class="fa fa-check"></i><b>1.2</b> Teoría de visualización de datos</a></li>
<li class="chapter" data-level="1.3" data-path="factor-de-engaño-y-chartjunk.html"><a href="factor-de-engaño-y-chartjunk.html"><i class="fa fa-check"></i><b>1.3</b> Factor de engaño y Chartjunk</a></li>
<li class="chapter" data-level="1.4" data-path="pequeños-múltiplos-y-densidad-gráfica.html"><a href="pequeños-múltiplos-y-densidad-gráfica.html"><i class="fa fa-check"></i><b>1.4</b> Pequeños múltiplos y densidad gráfica</a></li>
<li class="chapter" data-level="1.5" data-path="tinta-de-datos.html"><a href="tinta-de-datos.html"><i class="fa fa-check"></i><b>1.5</b> Tinta de datos</a></li>
<li class="chapter" data-level="1.6" data-path="decoración.html"><a href="decoración.html"><i class="fa fa-check"></i><b>1.6</b> Decoración</a></li>
<li class="chapter" data-level="1.7" data-path="percepción-de-escala.html"><a href="percepción-de-escala.html"><i class="fa fa-check"></i><b>1.7</b> Percepción de escala</a></li>
<li class="chapter" data-level="1.8" data-path="ejemplos-gráfica-de-minard.html"><a href="ejemplos-gráfica-de-minard.html"><i class="fa fa-check"></i><b>1.8</b> Ejemplos: gráfica de Minard</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introducción-a-r-y-al-paquete-ggplot2.html"><a href="introducción-a-r-y-al-paquete-ggplot2.html"><i class="fa fa-check"></i><b>2</b> Introducción a R y al paquete ggplot2</a><ul>
<li class="chapter" data-level="2.1" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html"><i class="fa fa-check"></i><b>2.1</b> R: primeros pasos</a><ul>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#r-en-análisis-de-datos"><i class="fa fa-check"></i>R en análisis de datos</a></li>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#paquetes-y-el-tidyverse"><i class="fa fa-check"></i>Paquetes y el Tidyverse</a></li>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#recursos"><i class="fa fa-check"></i>Recursos</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="visualización-con-ggplot2.html"><a href="visualización-con-ggplot2.html"><i class="fa fa-check"></i><b>2.2</b> Visualización con ggplot2</a><ul>
<li class="chapter" data-level="" data-path="visualización-con-ggplot2.html"><a href="visualización-con-ggplot2.html#recursos-1"><i class="fa fa-check"></i>Recursos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="manipulación-y-agrupación-de-datos.html"><a href="manipulación-y-agrupación-de-datos.html"><i class="fa fa-check"></i><b>3</b> Manipulación y agrupación de datos</a><ul>
<li class="chapter" data-level="3.1" data-path="transformación-de-datos.html"><a href="transformación-de-datos.html"><i class="fa fa-check"></i><b>3.1</b> Transformación de datos</a><ul>
<li class="chapter" data-level="" data-path="transformación-de-datos.html"><a href="transformación-de-datos.html#datos"><i class="fa fa-check"></i>Datos</a></li>
<li class="chapter" data-level="" data-path="transformación-de-datos.html"><a href="transformación-de-datos.html#filtrar"><i class="fa fa-check"></i>Filtrar</a></li>
<li class="chapter" data-level="" data-path="transformación-de-datos.html"><a href="transformación-de-datos.html#seleccionar"><i class="fa fa-check"></i>Seleccionar</a></li>
<li class="chapter" data-level="" data-path="transformación-de-datos.html"><a href="transformación-de-datos.html#ordenar"><i class="fa fa-check"></i>Ordenar</a></li>
<li class="chapter" data-level="" data-path="transformación-de-datos.html"><a href="transformación-de-datos.html#mutar"><i class="fa fa-check"></i>Mutar</a></li>
<li class="chapter" data-level="" data-path="transformación-de-datos.html"><a href="transformación-de-datos.html#summarise-y-resúmenes-por-grupo"><i class="fa fa-check"></i>Summarise y resúmenes por grupo</a></li>
<li class="chapter" data-level="" data-path="transformación-de-datos.html"><a href="transformación-de-datos.html#variables-por-grupo"><i class="fa fa-check"></i>Variables por grupo</a></li>
<li class="chapter" data-level="" data-path="transformación-de-datos.html"><a href="transformación-de-datos.html#verbos-de-dos-tablas"><i class="fa fa-check"></i>Verbos de dos tablas</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="datos-limpios.html"><a href="datos-limpios.html"><i class="fa fa-check"></i><b>3.2</b> Datos limpios</a><ul>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#limpieza-bases-de-datos"><i class="fa fa-check"></i>Limpieza bases de datos</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#los-encabezados-de-las-columanas-son-valores"><i class="fa fa-check"></i>Los encabezados de las columanas son valores</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#una-columna-asociada-a-más-de-una-variable"><i class="fa fa-check"></i>Una columna asociada a más de una variable</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#variables-almacenadas-en-filas-y-columnas"><i class="fa fa-check"></i>Variables almacenadas en filas y columnas</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#una-misma-unidad-observacional-está-almacenada-en-múltiples-tablas"><i class="fa fa-check"></i>Una misma unidad observacional está almacenada en múltiples tablas</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#otras-consideraciones"><i class="fa fa-check"></i>Otras consideraciones</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#recursos-adicionales"><i class="fa fa-check"></i>Recursos adicionales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="temas-selectos-de-r.html"><a href="temas-selectos-de-r.html"><i class="fa fa-check"></i><b>4</b> Temas selectos de R</a><ul>
<li class="chapter" data-level="4.1" data-path="funciones-e-iteración.html"><a href="funciones-e-iteración.html"><i class="fa fa-check"></i><b>4.1</b> Funciones e iteración</a><ul>
<li class="chapter" data-level="" data-path="funciones-e-iteración.html"><a href="funciones-e-iteración.html#funciones"><i class="fa fa-check"></i>Funciones</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="vectores.html"><a href="vectores.html"><i class="fa fa-check"></i><b>4.2</b> Vectores</a><ul>
<li class="chapter" data-level="" data-path="vectores.html"><a href="vectores.html#propiedades"><i class="fa fa-check"></i>Propiedades</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="iteración.html"><a href="iteración.html"><i class="fa fa-check"></i><b>4.3</b> Iteración</a><ul>
<li class="chapter" data-level="" data-path="iteración.html"><a href="iteración.html#ciclos-for"><i class="fa fa-check"></i>Ciclos for</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html"><i class="fa fa-check"></i><b>4.4</b> Rendimiento en R</a><ul>
<li class="chapter" data-level="" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html#diagnosticar"><i class="fa fa-check"></i>Diagnosticar</a></li>
<li class="chapter" data-level="" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html#estrategias-para-mejorar-desempeño"><i class="fa fa-check"></i>Estrategias para mejorar desempeño</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="lecturas-y-recursos-recomendados-de-r.html"><a href="lecturas-y-recursos-recomendados-de-r.html"><i class="fa fa-check"></i><b>4.5</b> Lecturas y recursos recomendados de R</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introducción-a-cálculo-de-probabilidades.html"><a href="introducción-a-cálculo-de-probabilidades.html"><i class="fa fa-check"></i><b>5</b> Introducción a Cálculo de Probabilidades</a><ul>
<li class="chapter" data-level="5.1" data-path="probabilidad-como-extensión-de-proporción.html"><a href="probabilidad-como-extensión-de-proporción.html"><i class="fa fa-check"></i><b>5.1</b> Probabilidad como extensión de proporción</a></li>
<li class="chapter" data-level="5.2" data-path="interpretación-frecuentista-de-probabilidad.html"><a href="interpretación-frecuentista-de-probabilidad.html"><i class="fa fa-check"></i><b>5.2</b> Interpretación frecuentista de probabilidad</a><ul>
<li class="chapter" data-level="" data-path="interpretación-frecuentista-de-probabilidad.html"><a href="interpretación-frecuentista-de-probabilidad.html#resultados-empíricos-acerca-de-frecuencias-relativas"><i class="fa fa-check"></i>Resultados empíricos acerca de frecuencias relativas</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="simulación-para-el-cálculo-de-probabilidades.html"><a href="simulación-para-el-cálculo-de-probabilidades.html"><i class="fa fa-check"></i><b>5.3</b> Simulación para el cálculo de probabilidades</a></li>
<li class="chapter" data-level="5.4" data-path="modelos-de-probabilidad-definición-general.html"><a href="modelos-de-probabilidad-definición-general.html"><i class="fa fa-check"></i><b>5.4</b> Modelos de probabilidad (definición general)</a><ul>
<li class="chapter" data-level="5.4.1" data-path="modelos-de-probabilidad-definición-general.html"><a href="modelos-de-probabilidad-definición-general.html#espacios-discretos"><i class="fa fa-check"></i><b>5.4.1</b> Espacios discretos</a></li>
<li class="chapter" data-level="5.4.2" data-path="modelos-de-probabilidad-definición-general.html"><a href="modelos-de-probabilidad-definición-general.html#espacios-continuos"><i class="fa fa-check"></i><b>5.4.2</b> Espacios continuos</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="probabilidad-definición-matemática.html"><a href="probabilidad-definición-matemática.html"><i class="fa fa-check"></i><b>5.5</b> Probabilidad: definición matemática</a><ul>
<li class="chapter" data-level="" data-path="probabilidad-definición-matemática.html"><a href="probabilidad-definición-matemática.html#propiedades-de-la-función-de-probabilidad"><i class="fa fa-check"></i>Propiedades de la función de probabilidad:</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html"><i class="fa fa-check"></i><b>5.6</b> Variables aleatorias</a><ul>
<li class="chapter" data-level="" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#distribución-de-probabilidad"><i class="fa fa-check"></i>Distribución de probabilidad</a></li>
<li class="chapter" data-level="" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#variables-aleatorias-continuas"><i class="fa fa-check"></i>Variables aleatorias continuas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bootstrap-no-paramétrico.html"><a href="bootstrap-no-paramétrico.html"><i class="fa fa-check"></i><b>6</b> Bootstrap no paramétrico</a><ul>
<li class="chapter" data-level="6.1" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html"><i class="fa fa-check"></i><b>6.1</b> El principio del plug-in</a><ul>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#muestras-aleatorias"><i class="fa fa-check"></i>Muestras aleatorias</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#función-de-distribución-empírica"><i class="fa fa-check"></i>Función de distribución empírica</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#parámetros-y-estadísticas"><i class="fa fa-check"></i>Parámetros y estadísticas</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#distribuciones-muestrales-y-errores-estándar"><i class="fa fa-check"></i>Distribuciones muestrales y errores estándar</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="el-estimador-bootstrap-del-error-estándar.html"><a href="el-estimador-bootstrap-del-error-estándar.html"><i class="fa fa-check"></i><b>6.2</b> El estimador bootstrap del error estándar</a><ul>
<li class="chapter" data-level="" data-path="el-estimador-bootstrap-del-error-estándar.html"><a href="el-estimador-bootstrap-del-error-estándar.html#variación-en-distribuciones-bootstrap"><i class="fa fa-check"></i>Variación en distribuciones bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>6.3</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="6.4" data-path="más-alla-de-muestras-aleatorias-simples.html"><a href="más-alla-de-muestras-aleatorias-simples.html"><i class="fa fa-check"></i><b>6.4</b> Más alla de muestras aleatorias simples</a></li>
<li class="chapter" data-level="6.5" data-path="bootstrap-en-r.html"><a href="bootstrap-en-r.html"><i class="fa fa-check"></i><b>6.5</b> Bootstrap en R</a></li>
<li class="chapter" data-level="6.6" data-path="conclusiones-y-observaciones.html"><a href="conclusiones-y-observaciones.html"><i class="fa fa-check"></i><b>6.6</b> Conclusiones y observaciones</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="teoría-básica-de-simulación.html"><a href="teoría-básica-de-simulación.html"><i class="fa fa-check"></i><b>7</b> Teoría básica de simulación</a><ul>
<li class="chapter" data-level="7.1" data-path="números-pseudoaleatorios.html"><a href="números-pseudoaleatorios.html"><i class="fa fa-check"></i><b>7.1</b> Números pseudoaleatorios</a><ul>
<li class="chapter" data-level="" data-path="números-pseudoaleatorios.html"><a href="números-pseudoaleatorios.html#generadores-congruenciales-y-mersenne-twister"><i class="fa fa-check"></i>Generadores congruenciales y Mersenne-Twister</a></li>
<li class="chapter" data-level="" data-path="números-pseudoaleatorios.html"><a href="números-pseudoaleatorios.html#pruebas-de-aleatoriedad"><i class="fa fa-check"></i>Pruebas de aleatoriedad</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html"><i class="fa fa-check"></i><b>7.2</b> Variables aleatorias</a><ul>
<li class="chapter" data-level="" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html#familias-discretas-importantes"><i class="fa fa-check"></i>Familias discretas importantes</a></li>
<li class="chapter" data-level="" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html#familias-continuas-importantes"><i class="fa fa-check"></i>Familias Continuas importantes</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="simulación-de-variables-aleatorias.html"><a href="simulación-de-variables-aleatorias.html"><i class="fa fa-check"></i><b>7.3</b> Simulación de variables aleatorias</a><ul>
<li class="chapter" data-level="" data-path="simulación-de-variables-aleatorias.html"><a href="simulación-de-variables-aleatorias.html#variables-aletaorias-discretas"><i class="fa fa-check"></i>Variables aletaorias discretas</a></li>
<li class="chapter" data-level="" data-path="simulación-de-variables-aleatorias.html"><a href="simulación-de-variables-aleatorias.html#aceptación-y-rechazo"><i class="fa fa-check"></i>Aceptación y rechazo</a></li>
<li class="chapter" data-level="" data-path="simulación-de-variables-aleatorias.html"><a href="simulación-de-variables-aleatorias.html#variables-aleatorias-continuas-2"><i class="fa fa-check"></i>Variables aleatorias continuas</a></li>
<li class="chapter" data-level="" data-path="simulación-de-variables-aleatorias.html"><a href="simulación-de-variables-aleatorias.html#aceptación-y-rechazo-1"><i class="fa fa-check"></i>Aceptación y rechazo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="simulación-de-modelos.html"><a href="simulación-de-modelos.html"><i class="fa fa-check"></i><b>8</b> Simulación de modelos</a><ul>
<li class="chapter" data-level="" data-path="simulación-de-modelos.html"><a href="simulación-de-modelos.html#para-qué-simular-de-un-modelo"><i class="fa fa-check"></i>¿Para qué simular de un modelo?</a></li>
<li class="chapter" data-level="8.1" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html"><i class="fa fa-check"></i><b>8.1</b> Distribuciones multivariadas</a><ul>
<li class="chapter" data-level="" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#regla-de-bayes"><i class="fa fa-check"></i>Regla de Bayes</a></li>
<li class="chapter" data-level="" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#independencia"><i class="fa fa-check"></i>Independencia</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="modelos-gráficos-y-simulación-predictiva.html"><a href="modelos-gráficos-y-simulación-predictiva.html"><i class="fa fa-check"></i><b>8.2</b> Modelos gráficos y simulación predictiva</a></li>
<li class="chapter" data-level="8.3" data-path="inferencia-visual.html"><a href="inferencia-visual.html"><i class="fa fa-check"></i><b>8.3</b> Inferencia visual</a><ul>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#inferencia"><i class="fa fa-check"></i>Inferencia</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#protocolos-de-inferencia-visual"><i class="fa fa-check"></i>Protocolos de inferencia visual</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#pruebas-de-hipótesis-típicas"><i class="fa fa-check"></i>Pruebas de hipótesis típicas</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#inferencia-visual-1"><i class="fa fa-check"></i>Inferencia visual</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#más-allá-que-permutación"><i class="fa fa-check"></i>Más allá que permutación</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#otras-consideraciones-1"><i class="fa fa-check"></i>Otras consideraciones</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="tamaño-de-muestracalculos-de-potencia.html"><a href="tamaño-de-muestracalculos-de-potencia.html"><i class="fa fa-check"></i><b>8.4</b> Tamaño de muestra/calculos de potencia</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="inferencia-paramétrica.html"><a href="inferencia-paramétrica.html"><i class="fa fa-check"></i><b>9</b> Inferencia paramétrica</a><ul>
<li class="chapter" data-level="9.1" data-path="máxima-verosimilitud.html"><a href="máxima-verosimilitud.html"><i class="fa fa-check"></i><b>9.1</b> Máxima verosimilitud</a><ul>
<li class="chapter" data-level="" data-path="máxima-verosimilitud.html"><a href="máxima-verosimilitud.html#propiedades-de-los-estimadores-de-máxima-verosimilitud"><i class="fa fa-check"></i>Propiedades de los estimadores de máxima verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="bootstrap-paramétrico.html"><a href="bootstrap-paramétrico.html"><i class="fa fa-check"></i><b>9.2</b> Bootstrap paramétrico</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="análisis-bayesiano.html"><a href="análisis-bayesiano.html"><i class="fa fa-check"></i><b>10</b> Análisis bayesiano</a><ul>
<li class="chapter" data-level="10.1" data-path="probabilidad-subjetiva.html"><a href="probabilidad-subjetiva.html"><i class="fa fa-check"></i><b>10.1</b> Probabilidad subjetiva</a></li>
<li class="chapter" data-level="10.2" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html"><i class="fa fa-check"></i><b>10.2</b> Regla de Bayes e inferencia bayesiana</a><ul>
<li class="chapter" data-level="" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html#regla-de-bayes-en-modelos-y-datos"><i class="fa fa-check"></i>Regla de Bayes en modelos y datos</a></li>
<li class="chapter" data-level="" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html#objetivos-de-la-inferencia"><i class="fa fa-check"></i>Objetivos de la inferencia</a></li>
<li class="chapter" data-level="" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html#cálculo-de-la-distribución-posterior"><i class="fa fa-check"></i>Cálculo de la distribución posterior</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="distribuciones-conjugadas.html"><a href="distribuciones-conjugadas.html"><i class="fa fa-check"></i><b>10.3</b> Distribuciones conjugadas</a><ul>
<li class="chapter" data-level="" data-path="distribuciones-conjugadas.html"><a href="distribuciones-conjugadas.html#ejemplo-bernoulli"><i class="fa fa-check"></i>Ejemplo: Bernoulli</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="aproximación-por-cuadrícula.html"><a href="aproximación-por-cuadrícula.html"><i class="fa fa-check"></i><b>10.4</b> Aproximación por cuadrícula</a></li>
<li class="chapter" data-level="10.5" data-path="mcmc.html"><a href="mcmc.html"><i class="fa fa-check"></i><b>10.5</b> MCMC</a><ul>
<li class="chapter" data-level="" data-path="mcmc.html"><a href="mcmc.html#introducción-metrópolis"><i class="fa fa-check"></i>Introducción Metrópolis</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="metrópolis.html"><a href="metrópolis.html"><i class="fa fa-check"></i><b>10.6</b> Metrópolis</a><ul>
<li class="chapter" data-level="" data-path="metrópolis.html"><a href="metrópolis.html#inferencia-de-dos-proporciones-binomiales"><i class="fa fa-check"></i>Inferencia de dos proporciones binomiales</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="muestreador-de-gibbs.html"><a href="muestreador-de-gibbs.html"><i class="fa fa-check"></i><b>10.7</b> Muestreador de Gibbs</a><ul>
<li class="chapter" data-level="" data-path="muestreador-de-gibbs.html"><a href="muestreador-de-gibbs.html#conclusiones-y-observaciones-metrópolis-y-gibbs"><i class="fa fa-check"></i>Conclusiones y observaciones Metrópolis y Gibbs</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html"><i class="fa fa-check"></i><b>10.8</b> HMC y Stan</a><ul>
<li class="chapter" data-level="" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html#muestreo-hmc"><i class="fa fa-check"></i>Muestreo HMC</a></li>
<li class="chapter" data-level="" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html#stan"><i class="fa fa-check"></i>Stan</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="diagnósticos-generales.html"><a href="diagnósticos-generales.html"><i class="fa fa-check"></i><b>10.9</b> Diagnósticos generales</a><ul>
<li class="chapter" data-level="" data-path="diagnósticos-generales.html"><a href="diagnósticos-generales.html#recomendaciones-generales"><i class="fa fa-check"></i>Recomendaciones generales</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="modelos-jerárquicos.html"><a href="modelos-jerárquicos.html"><i class="fa fa-check"></i><b>10.10</b> Modelos jerárquicos</a><ul>
<li class="chapter" data-level="" data-path="modelos-jerárquicos.html"><a href="modelos-jerárquicos.html#modelo-jerárquico-una-moneda"><i class="fa fa-check"></i>Modelo jerárquico una moneda</a></li>
<li class="chapter" data-level="" data-path="modelos-jerárquicos.html"><a href="modelos-jerárquicos.html#multiples-monedas-de-una-misma-fábrica"><i class="fa fa-check"></i>Multiples monedas de una misma fábrica</a></li>
<li class="chapter" data-level="" data-path="modelos-jerárquicos.html"><a href="modelos-jerárquicos.html#ejemplo-estimación-de-tasas-de-mortalidad"><i class="fa fa-check"></i>Ejemplo: estimación de tasas de mortalidad</a></li>
</ul></li>
<li class="chapter" data-level="10.11" data-path="inicialesy-reparametrización.html"><a href="inicialesy-reparametrización.html"><i class="fa fa-check"></i><b>10.11</b> Inicialesy Reparametrización</a><ul>
<li class="chapter" data-level="" data-path="inicialesy-reparametrización.html"><a href="inicialesy-reparametrización.html#iniciales-en-stan"><i class="fa fa-check"></i>Iniciales en Stan</a></li>
</ul></li>
<li class="chapter" data-level="10.12" data-path="reparametrización.html"><a href="reparametrización.html"><i class="fa fa-check"></i><b>10.12</b> Reparametrización</a><ul>
<li class="chapter" data-level="" data-path="reparametrización.html"><a href="reparametrización.html#ejemplo-el-embudo-de-neal"><i class="fa fa-check"></i>Ejemplo: El embudo de Neal</a></li>
<li class="chapter" data-level="" data-path="reparametrización.html"><a href="reparametrización.html#modelos-jerárquicos-y-parametrización-no-centrada"><i class="fa fa-check"></i>Modelos jerárquicos y parametrización no centrada</a></li>
</ul></li>
<li class="chapter" data-level="10.13" data-path="recursos-de-stan-y-paquetes-con-r.html"><a href="recursos-de-stan-y-paquetes-con-r.html"><i class="fa fa-check"></i><b>10.13</b> Recursos de Stan y paquetes con R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tareas.html"><a href="tareas.html"><i class="fa fa-check"></i>Tareas</a><ul>
<li class="chapter" data-level="" data-path="instalación-y-visualización.html"><a href="instalación-y-visualización.html"><i class="fa fa-check"></i>1. Instalación y visualización</a></li>
<li class="chapter" data-level="" data-path="transformación-de-datos-1.html"><a href="transformación-de-datos-1.html"><i class="fa fa-check"></i>2. Transformación de datos</a></li>
<li class="chapter" data-level="" data-path="unión-de-tablas-y-limpieza-de-datos.html"><a href="unión-de-tablas-y-limpieza-de-datos.html"><i class="fa fa-check"></i>3. Unión de tablas y limpieza de datos</a></li>
<li class="chapter" data-level="" data-path="programación-funcional-y-distribución-muestral.html"><a href="programación-funcional-y-distribución-muestral.html"><i class="fa fa-check"></i>4. Programación funcional y distribución muestral</a><ul>
<li class="chapter" data-level="" data-path="programación-funcional-y-distribución-muestral.html"><a href="programación-funcional-y-distribución-muestral.html#solución-bootstrap"><i class="fa fa-check"></i>Solución + bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bootstrap-conteo.html"><a href="bootstrap-conteo.html"><i class="fa fa-check"></i>5. Bootstrap conteo</a></li>
<li class="chapter" data-level="" data-path="respuesta-ejercicios-clase.html"><a href="respuesta-ejercicios-clase.html"><i class="fa fa-check"></i>Respuesta ejercicios clase</a></li>
<li class="chapter" data-level="" data-path="más-bootstrap.html"><a href="más-bootstrap.html"><i class="fa fa-check"></i>6. Más bootstrap</a></li>
<li class="chapter" data-level="" data-path="simulación-de-variables-aleatorias-1.html"><a href="simulación-de-variables-aleatorias-1.html"><i class="fa fa-check"></i>7. Simulación de variables aleatorias</a></li>
<li class="chapter" data-level="" data-path="distribuciones-multivariada-y-simulación.html"><a href="distribuciones-multivariada-y-simulación.html"><i class="fa fa-check"></i>8. Distribuciones multivariada y simulación</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual-y-simulación-e-modelos.html"><a href="inferencia-visual-y-simulación-e-modelos.html"><i class="fa fa-check"></i>9. Inferencia visual y simulación e modelos</a></li>
<li class="chapter" data-level="" data-path="simulación-muestra-y-bootstrap-paramétrico.html"><a href="simulación-muestra-y-bootstrap-paramétrico.html"><i class="fa fa-check"></i>10. Simulación muestra y bootstrap paramétrico</a></li>
<li class="chapter" data-level="" data-path="familias-conjugadas.html"><a href="familias-conjugadas.html"><i class="fa fa-check"></i>11-Familias conjugadas</a></li>
<li class="chapter" data-level="" data-path="metropolis-1.html"><a href="metropolis-1.html"><i class="fa fa-check"></i>12-Metropolis</a></li>
<li class="chapter" data-level="" data-path="modelos-jerárquicos-1.html"><a href="modelos-jerárquicos-1.html"><i class="fa fa-check"></i>13-Modelos jerárquicos</a></li>
<li class="chapter" data-level="" data-path="final.html"><a href="final.html"><i class="fa fa-check"></i>Final</a><ul>
<li class="chapter" data-level="" data-path="final.html"><a href="final.html#inferencia-gráfica"><i class="fa fa-check"></i>1. Inferencia gráfica</a></li>
<li class="chapter" data-level="" data-path="final.html"><a href="final.html#simulación-para-el-cálculo-de-tamaños-de-muestra"><i class="fa fa-check"></i>2. Simulación para el cálculo de tamaños de muestra</a></li>
<li class="chapter" data-level="" data-path="final.html"><a href="final.html#mcmc-1"><i class="fa fa-check"></i>3. MCMC</a></li>
<li class="chapter" data-level="" data-path="final.html"><a href="final.html#modelos-jerárquicos-y-stan"><i class="fa fa-check"></i>4. Modelos jerárquicos y Stan</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística Computacional</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hmc-y-stan" class="section level2">
<h2><span class="header-section-number">10.8</span> HMC y Stan</h2>
<blockquote>
<p>It appears to be quite a general principle that, whenever there is a
randomized way of doinf something, then there is a nonrandomized way that
delivers better performance but requires more thought. -E.T. Jaynes</p>
</blockquote>
<p>Stan es un programa para generar muestras de una distribución posterior de los
parámetros de un modelo, el nombre del programa hace referencia a <a href="https://en.wikipedia.org/wiki/Stanislaw_Ulam">Stanislaw Ulam (1904-1984)</a> que fue pionero en
los métodos de Monte Carlo. A diferencia de JAGS y BUGS, los pasos de la cadena
de Markov se generan con un método llamado <em>Monte Carlo Hamiltoniano</em> (HMC). HMC
es computacionalmente más costoso que Metropolis o Gibbs, sin embargo, sus
propuestas suelen ser más eficientes, y por consiguiente no necesita muestras
tan grandes. En particular cuando se ajustan modelos grandes y complejos (por
ejemplo, con variables con correlación alta) HMC supera a otros.</p>
<div id="muestreo-hmc" class="section level3 unnumbered">
<h3>Muestreo HMC</h3>
<p>El uso de HMC en estadística es reciente, sin embargo, gracias a Stan se ha
expandido rápidamente tanto en academia como industria. Desafortunadamente, la
teoría de HMC está desarrollada en términos de geometría diferencial, lo que
hace que su construcción formal requiera de matemáticas avanzadas. En estas
notas se presentan las ideas detrás de HMC siguiendo <span class="citation">Kruschke (<a href="#ref-kruschke">2015</a>)</span>, una referencia
con mayor detalle es <span class="citation">Betancourt (<a href="#ref-betancourt2017">2017</a>)</span> y para el uso de Stan vale la pena tener
siempre a la mano el <a href="https://mc-stan.org/docs/2_21/reference-manual/index.html">manual</a>.</p>
<p>Stan genera muestras de la posterior usando una variación del algoritmo de
Metrópolis. Recordemos como funciona el algoritmo de Metrópolis que vimos en
clase:</p>
<ol style="list-style-type: decimal">
<li><p>Tenemos una distribución objetivo <span class="math inline">\(p(\theta)\)</span> de la cual buscamos generar
muestras. Debemos ser capaces de calcular el valor de <span class="math inline">\(p(\theta)\)</span> para cualquier
valor candidato <span class="math inline">\(\theta\)</span>. La distribución objetivo <span class="math inline">\(p(\theta)\)</span> no tiene que
estar normalizada, típicamente <span class="math inline">\(p(\theta)\)</span> es la distribución posterior de
<span class="math inline">\(\theta\)</span> no normalizada, es decir, es el producto de la verosimilitud y la
inicial.</p></li>
<li>La muestra de la distribución objetivo se genera mediante una caminata
aleatoria a través del espacio de parámetros.
<ul>
<li>La caminata inicia en un lugar arbitrario (definido por el usuario). El
punto inicial debe ser tal que <span class="math inline">\(p(\theta)&gt;0\)</span>.</li>
<li>La caminata avanza en cada tiempo proponiendo un movimiento a una
nueva posición y después decidiendo si se acepta o no el valor propuesto. Las
distribuciones propuesta pueden tener muchas formas, el objetivo es que la
distribución propuesta explore el espacio de parámetros de manera eficiente.</li>
</ul></li>
<li><p>Una vez que tenemos un valor propuesto decidimos si aceptar calculando:</p></li>
</ol>
<p><span class="math display">\[p_{mover}=min\bigg( \frac{p(\theta_{propuesta})}{p(\theta_{actual})},1\bigg)\]</span></p>
<p>Y al final obtenemos valores representativos de la distribución objetivo
<span class="math inline">\(\{\theta_1,...,\theta_n\}\)</span>.</p>
<p>Notemos que en la versión de Metrópolis que estudiamos, la forma de la
distribución propuesta está centrada de manera simétrica en la posición actual.
Es decir, en un espacio paramétrico multidimensional, la distribución propuesta
podría ser una Normal multivariada, con la matriz de varianzas y covarianzas
seleccionada para mejorar la eficiencia en la aplicación particular.
La normal multivariada siempre esta centrada en la posición actual y siempre
tiene la misma forma, sin importar en que sección del espacio paramétrico
estemos ubicados. Esto puede llevar a ineficiencias, por ejemplo, si nos
ubicamos en las colas de la distribución posterior el paso propuesto con la
misma probabilidad nos aleja o acerca de la moda de la posterior. Otro ejemplo
es si la distriución posterior se curva a lo largo del espacio paramétrico, una
distribución propuesta (de forma fija) puede ser eficiente para una parte de la
posterior y poco eficiente para otra parte de la misma.</p>
<p>Por su parte HMC, usa una distribución propuesta que cambia dependiendo de la
posición actual. HMC utiliza el gradiente de la posterior y <em>envuelve</em> la
distribución propuesta hacia el gradiente, como se ve en la siguiente figura.</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb362-1" data-line-number="1">knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;img/hmc_proposals.png&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-44"></span>
<img src="img/hmc_proposals.png" alt="copyright(c) Kruschke, J. K. (2014). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. 2nd Edition. Academic Press / Elsevier" width="500px" />
<p class="caption">
Figure 10.1: copyright(c) Kruschke, J. K. (2014). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. 2nd Edition. Academic Press / Elsevier
</p>
</div>
<p>HMC genera un movimiento propuesta de manera análoga a rodar una canica en la
distribución posterior volteada (también conocida como potencial). El potencial
es el negativo del logaritmo de la densidad posterior, en las regiones donde la
posterior es alta el potencial es bajo, y en las la regiones donde la posterior
es plana el potencial es alto.</p>
<p>La propuesta se genera dando un golpecito la canica en una dirección aleatoria y
dejándola rodar cierto tiempo. En el caso del ejemplo de un solo parámetro la
dirección del golpecito inicial es hacia la izquierda o derecha, y la magnitud
se genera de manera aleatoria muestreando de una distrubución Gaussiana de media
cero. El golpecito impone un momento inicial a la canica, y al terminar el
tiempo se propone al algoritmo de Metrópilis la posición final de la canica. Es
fácil imaginar que la posición propuesta tenderá a estar en regiones de mayor
probabilidad posterior.</p>
<p>La última fila de la figura de arriba nos muestra un histograma de los pasos
propuestos, notemos que no está centrado en la posición actual sino que hay una
inclinación hacia la moda de la posterior.</p>
<p>Para distribuciones posteriores de dimensión alta con valles diagonales o
curveados, la dinámica de HMC generará valores propuesta mucho más prometedores
que una distribución propuesta simétrica (como la versión de Metrópolis que
implementamos) y mejores que un muestreador de Gibbs que puede <em>atorarse</em> en
paredes diagonales.</p>
<p>Es así que para pasar del algoritmo de Metrópolis que estudiamos a HMC se
modifica la probabilidad de aceptación para tener en cuenta no sola la densidad
posterior relativa, sino también el <em>momento</em> (denotado por <span class="math inline">\(\phi\)</span>) en las
posiciones actual y propuesta.</p>
<p><span class="math display">\[p_{aceptar}=min\bigg\{\frac{p(\theta_{propuesta}|x)p(\phi_{propuesta})}{p(\theta_{actual}|x)p(\phi_{actual})}, 1 \bigg\}\]</span></p>
<p>En un sistema continuo ideal la suma de la energía potencial y cinética (que
corresponden a <span class="math inline">\(-log(p(\theta|x))\)</span> y <span class="math inline">\(-log(p(\phi))\)</span>) es constante y por tanto
aceptaríamos todas las propuestas. Sin embargo, en la práctica las dinámicas
continuas se dicretizan a intervalos en el tiempo y los cálculos son solo
aproximados conllevando a que se rechacen algunas propuestas.</p>
<p>Si los pasos discretizados son pequeños entonces la aproximación será buena pero
se necesitarán más pasos para alejarse de una posición dada, y lo contrario si
los pasos son muy grandes. Por tanto se debe ajustar el tamaño del paso
(<span class="math inline">\(\varepsilon\)</span>) y el número de pasos. La duración de la trayectoria es el
producto del tamaño del paso y el número de pasos. Es usual buscar una tasa de
aceptación alrededor del <span class="math inline">\(65\%\)</span>, moviendo el tamaño de epsilon y compensando con
el número de pasos.</p>
<p>Es así que el tamaño del paso controla la suavidad de la trayectoria. También es
importante ajustar el número de pasos (es decir la duración del movimiento) pues
no queremos alejarnos demasiado o rodar de regreso a la posición actual. La
siguiente figura muestra varias trayectorias y notamos que muchas rebotan al
lugar inicial.</p>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb363-1" data-line-number="1">knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;img/hmc_proposals_2.png&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-45"></span>
<img src="img/hmc_proposals_2.png" alt="copyright(c) Kruschke, J. K. (2014). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. 2nd Edition. Academic Press / Elsevier" width="500px" />
<p class="caption">
Figure 10.2: copyright(c) Kruschke, J. K. (2014). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. 2nd Edition. Academic Press / Elsevier
</p>
</div>
<p>Para evitar las ineficiencias de dar vueltas en U, Stan incorpora un algoritmo
que generaliza la nación de vueltas en U a espacios de dimensión alta, y así
estima cuando parar las trayectorias antes de que reboten hacia la posición
inical. El algoritmo se llama <em>No U-turn Sampler</em> (NUTS).</p>
<p>Adicional a ajustar el tamaño del paso y número de pasos debemos ajustar la
desviación estándar del momento inicial. Si la desviación estandar del momento
es grande también lo será la desviación estándar de las propuestas. Nuevamente,
lo más eficiente será una desviación estándar ni muy grande ni muy chica. En
Stan la desviación estándar del momento se establece de manera adaptativa para
que coincida con la desviación estándar de la posterior.</p>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb364-1" data-line-number="1">knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;img/hmc_proposals_3.png&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-46"></span>
<img src="img/hmc_proposals_3.png" alt="copyright(c) Kruschke, J. K. (2014). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. 2nd Edition. Academic Press / Elsevier" width="500px" />
<p class="caption">
Figure 10.3: copyright(c) Kruschke, J. K. (2014). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. 2nd Edition. Academic Press / Elsevier
</p>
</div>
<p>Por último, para calcular la trayectoria propuesta debemos ser capaces de
calcular el gradiente de la densidad posterior en cualquier valor de los
parámetros. Para realizar esto de manera eficiente en espacios de dimensión alta
se debe derivar analíticamente, en el caso de modelos complejos las fórmulas se
derivan usando algoritmos avanzados.</p>
<p>El paper <a href="https://arxiv.org/pdf/1701.02434.pdf">A Conceptual Introduction to Hamiltonian Monte Carlo</a> de Michael Betancourt explica
conceptos e intuición detrás de HMC, y el porqué es apropiado en problemas de
alta dimensión.</p>
</div>
<div id="stan" class="section level3 unnumbered">
<h3>Stan</h3>
<p>Para instalar Stan sigue las instrucciones de <a href="http://mc-stan.org/users/interfaces/rstan.html">aquí</a>.
Nosotros usaremos el paquete <code>rstan</code>, <span class="citation">Guo, Gabry, and Goodrich (<a href="#ref-R-rstan">2019</a>)</span>.</p>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb365-1" data-line-number="1"><span class="kw">library</span>(rstan)</a>
<a class="sourceLine" id="cb365-2" data-line-number="2"></a>
<a class="sourceLine" id="cb365-3" data-line-number="3"><span class="co"># opcional para correr en paralelo</span></a>
<a class="sourceLine" id="cb365-4" data-line-number="4"><span class="kw">rstan_options</span>(<span class="dt">auto_write =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb365-5" data-line-number="5"><span class="kw">options</span>(<span class="dt">mc.cores =</span> parallel<span class="op">::</span><span class="kw">detectCores</span>())</a></code></pre></div>
<p>En Stan los programas se organizan mediante secuencias de bloques, cada uno
de estos bloques inicia con declaración de variables y después le siguen
enunciados.</p>
<p>El siguiente esqueleto ejemplifica los bloques disponibles, sin embargo, veremos
que no siempre se utilizan todos los bloques.</p>
<pre><code>functions {
  // ... function declarations and definitions ...
}
data {
  // ... declarations ...
}
transformed data {
   // ... declarations ... statements ...
}
parameters {
   // ... declarations ...
}
transformed parameters {
   // ... declarations ... statements ...
}
model {
   // ... declarations ... statements ...
}
generated quantities {
   // ... declarations ... statements ...
}</code></pre>
<p>Comenzamos con el ejemplo sencillo de estimar el sesgo de una moneda. El primer
paso es especificar el modelo en el lenguaje de Stan. Lo podemos guardar en un
archivo de texto separado o simplemente asignarlo a una variable en R.</p>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb367-1" data-line-number="1">modelo_bernoulli.stan &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb367-2" data-line-number="2"><span class="st">&#39;   </span></a>
<a class="sourceLine" id="cb367-3" data-line-number="3"><span class="st">data {</span></a>
<a class="sourceLine" id="cb367-4" data-line-number="4"><span class="st">    int&lt;lower=0&gt; N;</span></a>
<a class="sourceLine" id="cb367-5" data-line-number="5"><span class="st">    int y[N]; </span></a>
<a class="sourceLine" id="cb367-6" data-line-number="6"><span class="st">}</span></a>
<a class="sourceLine" id="cb367-7" data-line-number="7"><span class="st">parameters {</span></a>
<a class="sourceLine" id="cb367-8" data-line-number="8"><span class="st">    real&lt;lower=0,upper=1&gt; theta;</span></a>
<a class="sourceLine" id="cb367-9" data-line-number="9"><span class="st">} </span></a>
<a class="sourceLine" id="cb367-10" data-line-number="10"><span class="st">model {</span></a>
<a class="sourceLine" id="cb367-11" data-line-number="11"><span class="st">    theta ~ beta(1,1) ;</span></a>
<a class="sourceLine" id="cb367-12" data-line-number="12"><span class="st">    y ~ bernoulli(theta) ;</span></a>
<a class="sourceLine" id="cb367-13" data-line-number="13"><span class="st">}</span></a>
<a class="sourceLine" id="cb367-14" data-line-number="14"></a>
<a class="sourceLine" id="cb367-15" data-line-number="15"><span class="st">&#39;</span></a>
<a class="sourceLine" id="cb367-16" data-line-number="16"><span class="co"># notemos que los modelos de Stan deben terminar con una línea en blanco</span></a>
<a class="sourceLine" id="cb367-17" data-line-number="17"><span class="kw">cat</span>(modelo_bernoulli.stan, <span class="dt">file =</span> <span class="st">&quot;src/stan_files/modelo_bernoulli.stan&quot;</span>)</a></code></pre></div>
<p>Notemos que Stan permite operaciones vectorizadas, por lo que podemos
poner:</p>
<pre><code>y ~ bernoulli(theta) ;</code></pre>
<p>sin necesidad de hacer el ciclo <code>for</code>:</p>
<pre><code>for ( i in 1:N ) {
    y[i] ~ dbern(theta)
}</code></pre>
<p>Una vez que especificamos el modelo lo siguiente es traducir el modelo a código
de C++ y compilarlo. Para esto usamos la función <code>stan_model()</code> que puede
recibir el archivo de texto con la especificación del modelo.</p>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb370-1" data-line-number="1">stan_cpp &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;src/stan_files/modelo_bernoulli.stan&quot;</span>)</a></code></pre></div>
<p>O el objeto de R,</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb371-1" data-line-number="1">stan_cpp &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="dt">model_code =</span> modelo_bernoulli.stan)</a></code></pre></div>
<p>El paso de compilación puede tardar, pues Stan está calculando los gradientes
para las dinámicas Hamiltonianas.</p>
<p>Ahora cargamos los datos y usamos la función <code>sampling</code> para obtener las
simulaciones de la distribución posterior.</p>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb372-1" data-line-number="1">N =<span class="st"> </span><span class="dv">50</span> ; z =<span class="st"> </span><span class="dv">10</span> ; y =<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, z), <span class="kw">rep</span>(<span class="dv">0</span>, N <span class="op">-</span><span class="st"> </span>z))</a>
<a class="sourceLine" id="cb372-2" data-line-number="2"></a>
<a class="sourceLine" id="cb372-3" data-line-number="3"><span class="kw">set.seed</span>(<span class="dv">8979</span>)</a>
<a class="sourceLine" id="cb372-4" data-line-number="4">data_list &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">y =</span> y, <span class="dt">N =</span> N )</a>
<a class="sourceLine" id="cb372-5" data-line-number="5">stan_fit &lt;-<span class="st"> </span><span class="kw">sampling</span>(<span class="dt">object =</span> stan_cpp, <span class="dt">data =</span> data_list, <span class="dt">chains =</span> <span class="dv">3</span> , </a>
<a class="sourceLine" id="cb372-6" data-line-number="6">    <span class="dt">iter =</span> <span class="dv">1000</span> , <span class="dt">warmup =</span> <span class="dv">200</span>, <span class="dt">thin =</span> <span class="dv">1</span> )</a></code></pre></div>
<p>La función <code>summary()</code> nos da resúmenes de la distribución posterior de los
parámetros combinando las simulaciones de todas las cadenas y por cadena.</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb373-1" data-line-number="1">stan_fit</a>
<a class="sourceLine" id="cb373-2" data-line-number="2"><span class="co">#&gt; Inference for Stan model: modelo_bernoulli.</span></a>
<a class="sourceLine" id="cb373-3" data-line-number="3"><span class="co">#&gt; 3 chains, each with iter=1000; warmup=200; thin=1; </span></a>
<a class="sourceLine" id="cb373-4" data-line-number="4"><span class="co">#&gt; post-warmup draws per chain=800, total post-warmup draws=2400.</span></a>
<a class="sourceLine" id="cb373-5" data-line-number="5"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb373-6" data-line-number="6"><span class="co">#&gt;         mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat</span></a>
<a class="sourceLine" id="cb373-7" data-line-number="7"><span class="co">#&gt; theta   0.21    0.00 0.06   0.11   0.17   0.21   0.25   0.33   864    1</span></a>
<a class="sourceLine" id="cb373-8" data-line-number="8"><span class="co">#&gt; lp__  -27.35    0.02 0.75 -29.49 -27.52 -27.07 -26.88 -26.83   915    1</span></a>
<a class="sourceLine" id="cb373-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb373-10" data-line-number="10"><span class="co">#&gt; Samples were drawn using NUTS(diag_e) at Sun Dec  8 15:04:17 2019.</span></a>
<a class="sourceLine" id="cb373-11" data-line-number="11"><span class="co">#&gt; For each parameter, n_eff is a crude measure of effective sample size,</span></a>
<a class="sourceLine" id="cb373-12" data-line-number="12"><span class="co">#&gt; and Rhat is the potential scale reduction factor on split chains (at </span></a>
<a class="sourceLine" id="cb373-13" data-line-number="13"><span class="co">#&gt; convergence, Rhat=1).</span></a></code></pre></div>
<p>Una alternativa a usar las funciones <code>stan_model()</code> y <code>sampling()</code>, es compilar
y correr las cadenas de manera simultanea con la función <code>stan()</code>.</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb374-1" data-line-number="1">stan_fit_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">stan</span>(<span class="dt">file =</span> <span class="st">&#39;src/stan_files/modelo_bernoulli.stan&#39;</span>, <span class="dt">data =</span> data_list, </a>
<a class="sourceLine" id="cb374-2" data-line-number="2">    <span class="dt">chains =</span> <span class="dv">3</span>, <span class="dt">iter =</span> <span class="dv">1000</span> , <span class="dt">warmup =</span> <span class="dv">200</span>, <span class="dt">thin =</span> <span class="dv">1</span>)</a></code></pre></div>
<p>Podemos graficar las cadenas con la función <code>traceplot()</code>, esta gráfica nos
permire inspecconar la conducta del muestreador y evaluar si las cadenas se han
mezclado y olvidado el valor inicial.</p>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb375-1" data-line-number="1"><span class="kw">traceplot</span>(stan_fit)</a></code></pre></div>
<p><img src="09-analisis_bayesiano_files/figure-html/unnamed-chunk-54-1.png" width="672" style="display: block; margin: auto;" /></p>
<div id="ejemplo-normal-1" class="section level4 unnumbered">
<h4>Ejemplo normal</h4>
<p>Recordemos ahora el ejemplo normal con media y varianza desconocidas, para este
problema escribimos un muestreador de Gibbs, y ahora veremos como lo haríamos
con Stan y compararemos los resultados.</p>
<ol style="list-style-type: decimal">
<li>Escribimos el modelo en Stan:</li>
</ol>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb376-1" data-line-number="1">modelo_normal.stan &lt;-</a>
<a class="sourceLine" id="cb376-2" data-line-number="2"><span class="st">&#39;</span></a>
<a class="sourceLine" id="cb376-3" data-line-number="3"><span class="st">data {</span></a>
<a class="sourceLine" id="cb376-4" data-line-number="4"><span class="st">    int&lt;lower=0&gt; N;</span></a>
<a class="sourceLine" id="cb376-5" data-line-number="5"><span class="st">    vector[N] y; </span></a>
<a class="sourceLine" id="cb376-6" data-line-number="6"><span class="st">}</span></a>
<a class="sourceLine" id="cb376-7" data-line-number="7"><span class="st">parameters {</span></a>
<a class="sourceLine" id="cb376-8" data-line-number="8"><span class="st">    real mu;</span></a>
<a class="sourceLine" id="cb376-9" data-line-number="9"><span class="st">    real&lt;lower=0&gt; sigma2;</span></a>
<a class="sourceLine" id="cb376-10" data-line-number="10"><span class="st">} </span></a>
<a class="sourceLine" id="cb376-11" data-line-number="11"><span class="st">model {</span></a>
<a class="sourceLine" id="cb376-12" data-line-number="12"><span class="st">    y ~ normal(mu, sqrt(sigma2));</span></a>
<a class="sourceLine" id="cb376-13" data-line-number="13"><span class="st">    mu ~ normal(1.5, 4);</span></a>
<a class="sourceLine" id="cb376-14" data-line-number="14"><span class="st">    sigma2 ~ inv_gamma(3, 3);</span></a>
<a class="sourceLine" id="cb376-15" data-line-number="15"><span class="st">}</span></a>
<a class="sourceLine" id="cb376-16" data-line-number="16"></a>
<a class="sourceLine" id="cb376-17" data-line-number="17"><span class="st">&#39;</span></a>
<a class="sourceLine" id="cb376-18" data-line-number="18"></a>
<a class="sourceLine" id="cb376-19" data-line-number="19"><span class="kw">cat</span>(modelo_normal.stan, <span class="dt">file =</span> <span class="st">&quot;src/stan_files/modelo_normal.stan&quot;</span>)</a></code></pre></div>
<p>Especificamos la verosimilitud normal con media <span class="math inline">\(\mu\)</span> y varianza <span class="math inline">\(\sigma^2\)</span>,
notemos que en Stan los parámetros son la media y desviación estándar.</p>
<pre><code>y ~ normal(mu, sqrt(sigma2));</code></pre>
<p>Y al igual que en el ejemplo del muestreador de Gibbs usaremos iniciales Normal
para <span class="math inline">\(\mu\)</span> y Gamma inversa para <span class="math inline">\(\sigma^2\)</span>.</p>
<pre><code>mu ~ normal(1.5, 4);
sigma2 ~ inv_gamma(3, 3);</code></pre>
<p>Pasamos al paso de compilación:</p>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb379-1" data-line-number="1">stan_norm_cpp &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;src/stan_files/modelo_normal.stan&quot;</span>)</a></code></pre></div>
<p>El modelo ya esta especificado, pero aun falta indicar los datos observados.</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb380-1" data-line-number="1">N &lt;-<span class="st"> </span><span class="dv">50</span> <span class="co"># Observamos 20 realizaciones</span></a>
<a class="sourceLine" id="cb380-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">122</span>)</a>
<a class="sourceLine" id="cb380-3" data-line-number="3">y &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dv">2</span>, <span class="dv">2</span>) </a>
<a class="sourceLine" id="cb380-4" data-line-number="4"></a>
<a class="sourceLine" id="cb380-5" data-line-number="5">data_list &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">y =</span> y, <span class="dt">N =</span> N )</a>
<a class="sourceLine" id="cb380-6" data-line-number="6">norm_fit &lt;-<span class="st"> </span><span class="kw">sampling</span>(<span class="dt">object =</span> stan_norm_cpp, <span class="dt">data =</span> data_list,</a>
<a class="sourceLine" id="cb380-7" data-line-number="7">  <span class="dt">chains =</span> <span class="dv">3</span> , <span class="dt">iter =</span> <span class="dv">1000</span> , <span class="dt">warmup =</span> <span class="dv">500</span>)</a></code></pre></div>
<p>Y podemos ver intervalos de la distribución posterior de los parámetros.</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb381-1" data-line-number="1">norm_fit</a>
<a class="sourceLine" id="cb381-2" data-line-number="2"><span class="co">#&gt; Inference for Stan model: modelo_normal.</span></a>
<a class="sourceLine" id="cb381-3" data-line-number="3"><span class="co">#&gt; 3 chains, each with iter=1000; warmup=500; thin=1; </span></a>
<a class="sourceLine" id="cb381-4" data-line-number="4"><span class="co">#&gt; post-warmup draws per chain=500, total post-warmup draws=1500.</span></a>
<a class="sourceLine" id="cb381-5" data-line-number="5"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb381-6" data-line-number="6"><span class="co">#&gt;          mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat</span></a>
<a class="sourceLine" id="cb381-7" data-line-number="7"><span class="co">#&gt; mu       1.91    0.01 0.31   1.30   1.70   1.92   2.12   2.53  1071 1.00</span></a>
<a class="sourceLine" id="cb381-8" data-line-number="8"><span class="co">#&gt; sigma2   4.72    0.03 0.92   3.26   4.07   4.62   5.26   6.81   981 1.00</span></a>
<a class="sourceLine" id="cb381-9" data-line-number="9"><span class="co">#&gt; lp__   -71.04    0.05 0.99 -73.64 -71.39 -70.76 -70.33 -70.07   455 1.01</span></a>
<a class="sourceLine" id="cb381-10" data-line-number="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb381-11" data-line-number="11"><span class="co">#&gt; Samples were drawn using NUTS(diag_e) at Sun Dec  8 15:05:09 2019.</span></a>
<a class="sourceLine" id="cb381-12" data-line-number="12"><span class="co">#&gt; For each parameter, n_eff is a crude measure of effective sample size,</span></a>
<a class="sourceLine" id="cb381-13" data-line-number="13"><span class="co">#&gt; and Rhat is the potential scale reduction factor on split chains (at </span></a>
<a class="sourceLine" id="cb381-14" data-line-number="14"><span class="co">#&gt; convergence, Rhat=1).</span></a></code></pre></div>
<p>Podemos realizar graficas de las cadenas con más detalle (y con facilidad),
usando el paquete <code>bayesplot</code>.</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb382-1" data-line-number="1"><span class="kw">library</span>(bayesplot)</a>
<a class="sourceLine" id="cb382-2" data-line-number="2"><span class="co">#&gt; Error in library(bayesplot): there is no package called &#39;bayesplot&#39;</span></a>
<a class="sourceLine" id="cb382-3" data-line-number="3"></a>
<a class="sourceLine" id="cb382-4" data-line-number="4">norm_posterior_inc_warmup &lt;-<span class="st"> </span><span class="kw">extract</span>(norm_fit, <span class="dt">inc_warmup =</span> <span class="ot">TRUE</span>, </a>
<a class="sourceLine" id="cb382-5" data-line-number="5">  <span class="dt">permuted =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb382-6" data-line-number="6"></a>
<a class="sourceLine" id="cb382-7" data-line-number="7"><span class="kw">color_scheme_set</span>(<span class="st">&quot;mix-blue-red&quot;</span>)</a>
<a class="sourceLine" id="cb382-8" data-line-number="8"><span class="co">#&gt; Error in color_scheme_set(&quot;mix-blue-red&quot;): could not find function &quot;color_scheme_set&quot;</span></a>
<a class="sourceLine" id="cb382-9" data-line-number="9"><span class="kw">mcmc_trace</span>(norm_posterior_inc_warmup,  <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;mu&quot;</span>, <span class="st">&quot;sigma2&quot;</span>), <span class="dt">n_warmup =</span> <span class="dv">300</span>,</a>
<a class="sourceLine" id="cb382-10" data-line-number="10">  <span class="dt">facet_args =</span> <span class="kw">list</span>(<span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">labeller =</span> label_parsed)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb382-11" data-line-number="11"><span class="st">  </span><span class="kw">facet_text</span>(<span class="dt">size =</span> <span class="dv">15</span>)</a>
<a class="sourceLine" id="cb382-12" data-line-number="12"><span class="co">#&gt; Error in mcmc_trace(norm_posterior_inc_warmup, pars = c(&quot;mu&quot;, &quot;sigma2&quot;), : could not find function &quot;mcmc_trace&quot;</span></a></code></pre></div>
<p>Y podemos graficar la distribución posterior de los parámetros, con intervalos
de probabilidad.</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb383-1" data-line-number="1">norm_posterior &lt;-<span class="st"> </span><span class="kw">as.array</span>(norm_fit)</a>
<a class="sourceLine" id="cb383-2" data-line-number="2"></a>
<a class="sourceLine" id="cb383-3" data-line-number="3"><span class="kw">mcmc_areas</span>(norm_posterior, <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;mu&quot;</span>, <span class="st">&quot;sigma2&quot;</span>), <span class="dt">prob =</span> <span class="fl">0.8</span>, </a>
<a class="sourceLine" id="cb383-4" data-line-number="4">    <span class="dt">point_est =</span> <span class="st">&quot;median&quot;</span>, <span class="dt">adjust =</span> <span class="fl">1.4</span>) </a>
<a class="sourceLine" id="cb383-5" data-line-number="5"><span class="co">#&gt; Error in mcmc_areas(norm_posterior, pars = c(&quot;mu&quot;, &quot;sigma2&quot;), prob = 0.8, : could not find function &quot;mcmc_areas&quot;</span></a></code></pre></div>
<p><img src="img/manicule2.jpg" /> Realiza un histograma de la distribución predictiva
posterior. Construye un intervalo de <span class="math inline">\(95\%\)</span> de probabilidad para una predicción.
Tip: usa la función <code>extract()</code> para extraer las simulaciones del objeto
<code>stanfit</code>.</p>
</div>
</div>
</div>
<h3>Referencias</h3>
<div id="refs" class="references">
<div id="ref-betancourt2017">
<p>Betancourt, Michael. 2017. “A Conceptual Introduction to Hamiltonian Monte Carlo.” <a href="http://arxiv.org/abs/1701.02434" class="uri">http://arxiv.org/abs/1701.02434</a>.</p>
</div>
<div id="ref-R-rstan">
<p>Guo, Jiqiang, Jonah Gabry, and Ben Goodrich. 2019. <em>Rstan: R Interface to Stan</em>. <a href="https://CRAN.R-project.org/package=rstan" class="uri">https://CRAN.R-project.org/package=rstan</a>.</p>
</div>
<div id="ref-kruschke">
<p>Kruschke, John. 2015. <em>Doing Bayesian Data Analysis (Second Edition)</em>. Boston: Academic Press.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="muestreador-de-gibbs.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="diagnósticos-generales.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tereom/est-computacional-2019/edit/master/09-analisis_bayesiano.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
